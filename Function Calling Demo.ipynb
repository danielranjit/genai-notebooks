{
  "cells": [
    {
      "cell_type": "code",
      "id": "Tv4MtvgHx7Pkgxq7VMMmkDii",
      "metadata": {
        "tags": [],
        "id": "Tv4MtvgHx7Pkgxq7VMMmkDii"
      },
      "source": [
        "!pip3 install --upgrade --user google-cloud-aiplatform==1.55.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "sO1EkkYlP9Bn"
      },
      "id": "sO1EkkYlP9Bn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "\n",
        "PROJECT_ID = ! gcloud config get-value project\n",
        "PROJECT_ID = PROJECT_ID[0]\n",
        "LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
        "\n",
        "# define project information manually if the above code didn't work\n",
        "if PROJECT_ID == \"(unset)\":\n",
        "  PROJECT_ID = \"[your-project-id]\" # @param {type:\"string\"}\n",
        "\n",
        "print(PROJECT_ID)\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "dBAF_tCwQGrY"
      },
      "id": "dBAF_tCwQGrY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from vertexai.generative_models import (\n",
        "    Content,\n",
        "    FunctionDeclaration,\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    Part,\n",
        "    Tool,\n",
        ")"
      ],
      "metadata": {
        "id": "MBEn14reQNJA"
      },
      "id": "MBEn14reQNJA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiply(a:float, b:float):\n",
        "    \"\"\"returns a * b.\"\"\"\n",
        "    print(\"Calling Multiply function\")\n",
        "    return a * b\n",
        "\n",
        "def add(a:float, b:float):\n",
        "    \"\"\"returns a + b.\"\"\"\n",
        "    print(\"Calling Add function\")\n",
        "    return a + b\n",
        "\n",
        "\n",
        "multiply_info = FunctionDeclaration(\n",
        "    name=\"multiply\",\n",
        "    description=\"Multiplies two numbers and returns the result\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n",
        "            \"b\": {\"type\": \"number\", \"description\": \"Second number\"}\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "add_info = FunctionDeclaration(\n",
        "    name=\"add\",\n",
        "    description=\"Adds two numbers and returns the result\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n",
        "            \"b\": {\"type\": \"number\", \"description\": \"Second number\"}\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "math_tool = Tool(\n",
        "    function_declarations=[\n",
        "        multiply_info,\n",
        "        add_info\n",
        "    ],\n",
        ")\n",
        "\n",
        "model = GenerativeModel(\n",
        "    \"gemini-1.5-pro-001\",\n",
        "    system_instruction=[\"\"\"Answer the user's question,\n",
        "    but do not do any math yourself.\"\"\"],\n",
        "    tools=[math_tool]\n",
        "  )"
      ],
      "metadata": {
        "id": "gqSSFGQ8Qbj5"
      },
      "id": "gqSSFGQ8Qbj5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_response(response):\n",
        "\n",
        "  # If there is a function call then invoke it\n",
        "  # Otherwise print the response.\n",
        "  if response.candidates[0].function_calls:\n",
        "    function_call = response.candidates[0].function_calls[0]\n",
        "  else:\n",
        "    print(response.text)\n",
        "    return\n",
        "\n",
        "\n",
        "  if function_call.name == \"multiply\":\n",
        "      # Extract the arguments to use in your function\n",
        "      a = function_call.args[\"a\"]\n",
        "      b = function_call.args[\"b\"]\n",
        "\n",
        "      # Call your function\n",
        "      result = multiply(a, b)\n",
        "\n",
        "      # Send the result back to the model\n",
        "      response = chat.send_message(\"{0}\".format(result))\n",
        "\n",
        "      # Recursive call\n",
        "      handle_response(response)\n",
        "\n",
        "  elif function_call.name == \"add\":\n",
        "      # Extract the arguments to use in your function\n",
        "      a = function_call.args[\"a\"]\n",
        "      b = function_call.args[\"b\"]\n",
        "\n",
        "      # Call your function\n",
        "      result = add(a, b)\n",
        "\n",
        "      # Send the result back to the model\n",
        "      response = chat.send_message(\"{0}\".format(result))\n",
        "      # Recursive call\n",
        "      handle_response(response)\n",
        "  else:\n",
        "      # Shouldn't get here\n",
        "      print(function_call)\n"
      ],
      "metadata": {
        "id": "q5Uxdw_UdxdY"
      },
      "id": "q5Uxdw_UdxdY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat()"
      ],
      "metadata": {
        "id": "dJjjyWaZkjUr"
      },
      "id": "dJjjyWaZkjUr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\"Tell me a joke?\")\n",
        "# print(response)\n",
        "handle_response(response)"
      ],
      "metadata": {
        "id": "jjiTjlC6c8wu"
      },
      "id": "jjiTjlC6c8wu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\"I have 7 pizzas each with 16 slices. How many slices do I have?\")\n",
        "\n",
        "# print(response)\n",
        "handle_response(response)"
      ],
      "metadata": {
        "id": "QZlzDWbhYy8z"
      },
      "id": "QZlzDWbhYy8z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\"\"\"\n",
        "Doug brought 3 pizzas.\n",
        "Andrew brought 4 pizzas.\n",
        "How many pizzas did they bring together?\n",
        "\"\"\")\n",
        "\n",
        "handle_response(response)"
      ],
      "metadata": {
        "id": "KPSLreKPj9Wr"
      },
      "id": "KPSLreKPj9Wr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\"\"\"\n",
        "Doug brought 3 pizzas.\n",
        "Andrew brought 4 pizzas.\n",
        "There are 16 slices per pizza.\n",
        "How many slices are there?\n",
        "\"\"\")\n",
        "\n",
        "handle_response(response)"
      ],
      "metadata": {
        "id": "dWXWuEbnmoaO"
      },
      "id": "dWXWuEbnmoaO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\"\"\"\n",
        "Doug brought 4 pizzas, but Andrew dropped 2 on the ground.\n",
        "How many pizzas are left?\n",
        "\"\"\")\n",
        "\n",
        "# print(response)\n",
        "handle_response(response)"
      ],
      "metadata": {
        "id": "NaYgNrN1EpbK"
      },
      "id": "NaYgNrN1EpbK",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "Function Calling Demo"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}