{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Build a RAG System with Grounding using LangChain and Agent Builder Data Stores"
      ],
      "metadata": {
        "id": "LVvUIOTMDcOm"
      },
      "id": "LVvUIOTMDcOm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36810292-20fe-4627-88a4-5727256a9d20",
      "metadata": {
        "tags": [],
        "id": "36810292-20fe-4627-88a4-5727256a9d20"
      },
      "outputs": [],
      "source": [
        "! pip install -q --user google-cloud-aiplatform google-cloud-discoveryengine langchain-google-vertexai langchain-google-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bb60b92-6b99-4b5a-b31b-59d8cee4777e",
      "metadata": {
        "tags": [],
        "id": "4bb60b92-6b99-4b5a-b31b-59d8cee4777e"
      },
      "outputs": [],
      "source": [
        "# Restart kernel after packages are installed so that your environment can access the new packages\n",
        "import IPython\n",
        "import time\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b18b6155-b8b1-4de3-a86b-4366b474ef87",
      "metadata": {
        "tags": [],
        "id": "b18b6155-b8b1-4de3-a86b-4366b474ef87"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "import langchain\n",
        "\n",
        "PROJECT_ID = ! gcloud config get-value project\n",
        "PROJECT_ID = PROJECT_ID[0]\n",
        "LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
        "\n",
        "# define project information manually if the above code didn't work\n",
        "if PROJECT_ID == \"(unset)\":\n",
        "  PROJECT_ID = \"[your-project-id]\" # @param {type:\"string\"}\n",
        "\n",
        "print(PROJECT_ID)\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "\n",
        "print(f\"LangChain version: {langchain.__version__}\")\n",
        "print(f\"Vertex AI SDK version: {vertexai.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prerequisites\n",
        "\n",
        "You need to create a Data Store and Search app in Agent Builder.\n",
        "\n",
        "The Data Store should use the following Cloud Storage location:\n",
        "\n",
        "`gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs`\n",
        "\n",
        "Make sure to enable Enterprise features when creating the Search App."
      ],
      "metadata": {
        "id": "mLu_a5GZ_Xpa"
      },
      "id": "mLu_a5GZ_Xpa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24aab7ad-e4ff-4d13-ac0e-9ee552154673",
      "metadata": {
        "tags": [],
        "id": "24aab7ad-e4ff-4d13-ac0e-9ee552154673"
      },
      "outputs": [],
      "source": [
        "# Find your Data Store ID in the Agent Builder console.\n",
        "DATA_STORE_ID = \"qna-unstructured-datastore_1717079477615\"  # @param {type:\"string\"}\n",
        "DATA_STORE_LOCATION = \"global\"  # @param {type:\"string\"}\n",
        "\n",
        "MODEL = \"gemini-1.0-pro\"  # @param {type:\"string\"}\n",
        "\n",
        "if PROJECT_ID == \"YOUR_PROJECT_ID\" or DATA_STORE_ID == \"YOUR_DATA_STORE_ID\":\n",
        "    raise ValueError(\n",
        "        \"Please set the PROJECT_ID, DATA_STORE_ID constants to reflect your environment.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d29805c-8f37-407b-b39d-7916592b29a4",
      "metadata": {
        "tags": [],
        "id": "1d29805c-8f37-407b-b39d-7916592b29a4"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "from langchain_google_vertexai import VertexAI\n",
        "from langchain_google_community import VertexAISearchRetriever\n",
        "from langchain_google_community import VertexAIMultiTurnSearchRetriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cda55d0-42e9-4c90-9638-ce0436458dee",
      "metadata": {
        "tags": [],
        "id": "4cda55d0-42e9-4c90-9638-ce0436458dee"
      },
      "outputs": [],
      "source": [
        "llm = VertexAI(model_name=MODEL)\n",
        "\n",
        "# The retriever has the magic to search the\n",
        "# Data Store based on the user's question\n",
        "retriever = VertexAISearchRetriever(\n",
        "    project_id=PROJECT_ID,\n",
        "    location_id=DATA_STORE_LOCATION,\n",
        "    data_store_id=DATA_STORE_ID,\n",
        "    get_extractive_answers=True,\n",
        "    max_documents=10,\n",
        "    max_extractive_segment_count=1,\n",
        "    max_extractive_answer_count=5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use RetrievalQA to Ask the Question"
      ],
      "metadata": {
        "id": "SynLKCJDAmwL"
      },
      "id": "SynLKCJDAmwL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cabc4e67-ab14-410a-8862-8c2b1f02de17",
      "metadata": {
        "tags": [],
        "id": "cabc4e67-ab14-410a-8862-8c2b1f02de17"
      },
      "outputs": [],
      "source": [
        "search_query = \"What was Alphabet's Revenue in Q2 2021?\"\n",
        "\n",
        "retrieval_qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=retriever\n",
        ")\n",
        "retrieval_qa.invoke(search_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Include Grounding Data\n",
        "\n",
        "Add `return_source_documents=True` to see the documents used to answer the question"
      ],
      "metadata": {
        "id": "BMEr8jYlA27x"
      },
      "id": "BMEr8jYlA27x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bfd21d4-7da4-4c66-a4df-f5c06abca598",
      "metadata": {
        "tags": [],
        "id": "6bfd21d4-7da4-4c66-a4df-f5c06abca598"
      },
      "outputs": [],
      "source": [
        "retrieval_qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "results = retrieval_qa.invoke(search_query)\n",
        "\n",
        "print(\"*\" * 80)\n",
        "print(results[\"result\"])\n",
        "print(\"*\" * 80)\n",
        "for doc in results[\"source_documents\"]:\n",
        "    print(\"-\" * 80)\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Include Grounding Sources with the Results"
      ],
      "metadata": {
        "id": "jdG8mCilBd1h"
      },
      "id": "jdG8mCilBd1h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62ac81d5-2891-4e5f-9253-10a46e311d75",
      "metadata": {
        "tags": [],
        "id": "62ac81d5-2891-4e5f-9253-10a46e311d75"
      },
      "outputs": [],
      "source": [
        "retrieval_qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=retriever\n",
        ")\n",
        "\n",
        "retrieval_qa_with_sources.invoke(search_query, return_only_outputs=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Turn Retriever allows for followup questions"
      ],
      "metadata": {
        "id": "Zht0nigEBjRy"
      },
      "id": "Zht0nigEBjRy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84bb837c-cea3-42a6-aa1a-c073ef17c25f",
      "metadata": {
        "tags": [],
        "id": "84bb837c-cea3-42a6-aa1a-c073ef17c25f"
      },
      "outputs": [],
      "source": [
        "multi_turn_retriever = VertexAIMultiTurnSearchRetriever(\n",
        "    project_id=PROJECT_ID, location_id=DATA_STORE_LOCATION, data_store_id=DATA_STORE_ID\n",
        ")\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "conversational_retrieval = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm, retriever=multi_turn_retriever, memory=memory\n",
        ")\n",
        "\n",
        "search_query = \"What were alphabet revenues in 2022?\"\n",
        "\n",
        "result = conversational_retrieval.invoke(search_query)\n",
        "print(result[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb51480d-b602-4b15-8b85-ddab63091228",
      "metadata": {
        "tags": [],
        "id": "cb51480d-b602-4b15-8b85-ddab63091228"
      },
      "outputs": [],
      "source": [
        "new_query = \"What about costs and expenses?\"\n",
        "result = conversational_retrieval.invoke(new_query)\n",
        "print(result[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c14aea82-2020-46b5-a0c4-65aa845aa359",
      "metadata": {
        "tags": [],
        "id": "c14aea82-2020-46b5-a0c4-65aa845aa359"
      },
      "outputs": [],
      "source": [
        "new_query = \"Is this more than in 2021?\"\n",
        "\n",
        "result = conversational_retrieval.invoke(new_query)\n",
        "print(result[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Custom Prompt"
      ],
      "metadata": {
        "id": "J56uNJf_Bya-"
      },
      "id": "J56uNJf_Bya-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd45a867-d680-4871-a5db-3eba4cf469af",
      "metadata": {
        "tags": [],
        "id": "fd45a867-d680-4871-a5db-3eba4cf469af"
      },
      "outputs": [],
      "source": [
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True\n",
        ")\n",
        "\n",
        "# This just shows the default prompt\n",
        "print(qa.combine_documents_chain.llm_chain.prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "399982eb-7a0b-4be8-80c5-6c8dbc0fd88d",
      "metadata": {
        "tags": [],
        "id": "399982eb-7a0b-4be8-80c5-6c8dbc0fd88d"
      },
      "outputs": [],
      "source": [
        "# Create a custom prompt template.\n",
        "# Note: it instructs the model to return a 1 word answer\n",
        "prompt_template = \"\"\"Use the context to answer the question at the end.\n",
        "You must always use the context and context only to answer the question. Never try to make up an answer. If the context is empty or you do not know the answer, just say \"I don't know\".\n",
        "The answer should consist of only 1 word and not a sentence.\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "Helpful Answer:\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "# Specify the custom prompt template in the chain\n",
        "qa_chain = RetrievalQA.from_llm(\n",
        "    llm=llm, prompt=prompt, retriever=retriever, return_source_documents=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3918f1bc-c674-45c5-bf38-3c01f21d0186",
      "metadata": {
        "tags": [],
        "id": "3918f1bc-c674-45c5-bf38-3c01f21d0186"
      },
      "outputs": [],
      "source": [
        "# Show the custom prompt template just to show it worked.\n",
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69c98708-44ba-4c73-8bd7-d9ab13d7393e",
      "metadata": {
        "tags": [],
        "id": "69c98708-44ba-4c73-8bd7-d9ab13d7393e"
      },
      "outputs": [],
      "source": [
        "search_query = \"Were 2020 EMEA revenues higher than 2020 APAC revenues?\"\n",
        "\n",
        "results = qa_chain.invoke(search_query)\n",
        "\n",
        "print(\"*\" * 80)\n",
        "print(results[\"result\"])\n",
        "print(\"*\" * 80)\n",
        "for doc in results[\"source_documents\"]:\n",
        "    print(\"-\" * 80)\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa19dc15-5c75-490d-9171-417f1eca8544",
      "metadata": {
        "id": "aa19dc15-5c75-490d-9171-417f1eca8544"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": ".m121",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m121"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel) (Local)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "name": "LangChain QA with Data Store"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}