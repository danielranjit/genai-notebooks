{
  "cells": [
    {
      "cell_type": "code",
      "id": "EA7stuSTVZrdRvY7bdY6UL6D",
      "metadata": {
        "tags": [],
        "id": "EA7stuSTVZrdRvY7bdY6UL6D"
      },
      "source": [
        "!pip install openai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# Prompt the user for the API key\n",
        "os.environ['OPENAI_API_KEY'] = getpass.getpass(\"Enter your API key: \")"
      ],
      "metadata": {
        "id": "4jQvDGov0xi8"
      },
      "id": "4jQvDGov0xi8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use GPT 3.5 to return a response"
      ],
      "metadata": {
        "id": "gyS2bB6j_qO_"
      },
      "id": "gyS2bB6j_qO_"
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "def generate_response(context, prompt):\n",
        "  client = OpenAI()\n",
        "\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": context},\n",
        "      {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "  )\n",
        "  return completion.choices[0].message"
      ],
      "metadata": {
        "id": "1l6oSbkO398S"
      },
      "id": "1l6oSbkO398S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"You tell funny Jokes in the style of Jerry Seinfeld\"\n",
        "prompt = \"Tell me a joke about the airport.\"\n",
        "\n",
        "response = generate_response(context, prompt)\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "iithRTeb4sXa"
      },
      "id": "iithRTeb4sXa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change the Temperature"
      ],
      "metadata": {
        "id": "UFsLpdxGhr_T"
      },
      "id": "UFsLpdxGhr_T"
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Tell me a joke\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=1.5,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "xHz3xZfXhuvK"
      },
      "execution_count": null,
      "outputs": [],
      "id": "xHz3xZfXhuvK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use GPT 4"
      ],
      "metadata": {
        "id": "dgmAJPAQ_0BT"
      },
      "id": "dgmAJPAQ_0BT"
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "def generate_response(context, prompt):\n",
        "  client = OpenAI()\n",
        "\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo-preview\",\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": context},\n",
        "      {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "  )\n",
        "  return completion.choices[0].message"
      ],
      "metadata": {
        "id": "z6rtO6Wt_yw-"
      },
      "execution_count": null,
      "outputs": [],
      "id": "z6rtO6Wt_yw-"
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"You tell funny Jokes in the style of Jerry Seinfeld\"\n",
        "prompt = \"Tell me a joke about the airport.\"\n",
        "\n",
        "response = generate_response(context, prompt)\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "J4vOE6B5AHRu"
      },
      "execution_count": null,
      "outputs": [],
      "id": "J4vOE6B5AHRu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set the Temperature"
      ],
      "metadata": {
        "id": "2o4sRwO0AuQo"
      },
      "id": "2o4sRwO0AuQo"
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "def generate_response(context, prompt, temperature=1.0):\n",
        "  client = OpenAI()\n",
        "\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo-preview\",\n",
        "    temperature=temperature,\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": context},\n",
        "      {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "  )\n",
        "  return completion.choices[0].message"
      ],
      "metadata": {
        "id": "182-LXUEAqU9"
      },
      "id": "182-LXUEAqU9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"You tell funny Jokes in the style of Jerry Seinfeld\"\n",
        "prompt = \"Tell me a joke about the airport.\"\n",
        "\n",
        "response = generate_response(context, prompt, temperature=0.1)\n",
        "print(response.content)\n",
        "display(response)"
      ],
      "metadata": {
        "id": "cwLXHPk-Awlb"
      },
      "execution_count": null,
      "outputs": [],
      "id": "cwLXHPk-Awlb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Context"
      ],
      "metadata": {
        "id": "_PC_nKp4lNEo"
      },
      "id": "_PC_nKp4lNEo"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\", \"content\": \"You are a Python coding Chatbot.\",\n",
        "      \"role\": \"user\", \"content\": \"write a function to convert Fahrenheit to Celsius\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=1\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "FdhYguz1lM1L"
      },
      "execution_count": null,
      "outputs": [],
      "id": "FdhYguz1lM1L"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Variables"
      ],
      "metadata": {
        "id": "dA1NFBOj6KXM"
      },
      "id": "dA1NFBOj6KXM"
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\"\"\n",
        "You are a Python coding Chatbot.\n",
        "Unless told otherwise, all answers should be in Python.\n",
        "Always use Python best practices as defined by the `PEP 8` standard.\n",
        "Don't answer questions not related to Computers or Programming.\n",
        "\"\"\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "Create a class that converts Fahrenheit to Celsius and Visa Versa.\n",
        "Also, create a test fixture to test the class.\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\", \"content\":  context,\n",
        "      \"role\": \"user\", \"content\": prompt\n",
        "    }\n",
        "  ],\n",
        "  temperature=1,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "HSHMvg_Ihuxa"
      },
      "execution_count": null,
      "outputs": [],
      "id": "HSHMvg_Ihuxa"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You are a Python coding Chatbot.\\nUnless told otherwise, all answers should be in Python.\\nAlways use Python best practices as defined by the `PEP 8` standard.\\nDon't answer questions that are not related to computers or programming.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Write a class that converts Fahrenheit to Celsius\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": \"Sure, here is a basic Python class that converts Fahrenheit to Celsius:\\n\\n```python\\nclass TemperatureConverter:\\n    @staticmethod\\n    def fahrenheit_to_celsius(fahrenheit):\\n        return (fahrenheit - 32) * 5.0/9.0\\n\\n# usage\\nconverter = TemperatureConverter()\\nprint(converter.fahrenheit_to_celsius(68))  # should print 20.0\\n```\\n\\nThis class has a static method `fahrenheit_to_celsius()`. It takes a temperature in Fahrenheit as an argument and return its equivalent in Celsius. You can use it by creating an instance of `TemperatureConverter` and calling the method `fahrenheit_to_celsius()`.\\n\\nPlease note that the conversion formula from Fahrenheit to Celsius is `(Fahrenheit - 32) * 5/9`.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Now write unit tests for that class\"\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "DPMIJVbrr7yP"
      },
      "execution_count": null,
      "outputs": [],
      "id": "DPMIJVbrr7yP"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "Basic GPT Code"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}